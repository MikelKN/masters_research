{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#print long strings without truncating in pandas\n",
    "pd.options.display.max_colwidth = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "movie_dataset = pd.read_csv(r\"C:\\Users\\mikel\\OneDrive\\Research_2020\\IMDB_Dataset.csv\")\n",
    "clothing_dataset = pd.read_csv(r\"C:\\Users\\mikel\\OneDrive\\Research_2020\\Womens_Clothing_E-Commerce_Reviews.csv\", index_col = 0)\n",
    "food_dataset = pd.read_csv(r\"C:\\Users\\mikel\\OneDrive\\Research_2020\\Amazon_fine_food_customer_reviews.csv\", index_col =[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at each of these datasets one at a time \n",
    "\n",
    "MOVIE DATASET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of the movie dataset is: {}\".format (movie_dataset.shape))\n",
    "print('\\nSome sample datapoint:\\n')\n",
    "\n",
    "movie_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets get how balanced our movie dataset is\n",
    "movie_dataset.sentiment.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our movie dataset is equally balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we have any nans?\n",
    "#which columns have nans\n",
    "movie_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets convert the sentiments from categorical to numerical features\n",
    "le = LabelEncoder()\n",
    "movie_dataset['sentiment'] = le.fit_transform(movie_dataset['sentiment'])\n",
    "movie_dataset.rename(columns = {'review':'Text', 'sentiment':'ratings'}, inplace=True)\n",
    "#movie_dataset.rename(columns = {'sentiment':'ratings'}, inplace=True)\n",
    "\n",
    "movie_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Women E-ommerce clothing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of the women dataset is: {}\".format (clothing_dataset.shape))\n",
    "print('\\nSome sample datapoint:\\n')\n",
    "\n",
    "clothing_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE are interested in only 2 columns in this dataset. So we will drop some of the columns\n",
    "\n",
    "clothing_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_dataset.drop([col for col in clothing_dataset.columns if col not in ['Review Text', 'Rating']], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_dataset.Rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we have any null/empty cell\n",
    "#which columns have nans\n",
    "clothing_dataset.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping all the empty/ null cell from the clothing dataset\n",
    "clothing_dataset = clothing_dataset[~clothing_dataset['Review Text'].isnull()]\n",
    "\n",
    "clothing_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we shall consider all ratings 1, 2 as negative reviews and reviews 4, 5 as positive reviews\n",
    "#All reviews with Rating = 3 shall be considered neutrl reviews and for simplicity, shall be dropped.\n",
    "\n",
    "clothing_reviews=clothing_dataset[clothing_dataset.Rating!=3]\n",
    "clothing_reviews[\"ratings\"]= clothing_dataset[\"Rating\"].apply(lambda x: 1 if x > 3  else 0)\n",
    "clothing_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_reviews=clothing_reviews.drop(\"Rating\",axis=1)\n",
    "clothing_reviews.rename(columns = {'Review Text':'Text'}, inplace=True)\n",
    "\n",
    "clothing_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_reviews.ratings.value_counts(normalize = True)\n",
    "# this dataset is very imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'ratings', data = clothing_reviews)\n",
    "ax.set_title('Ratings distribution for women clothing dataset');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon fine food dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dataset.drop([col for col in food_dataset.columns if col not in ['Text','Score']], axis=1, inplace=True)\n",
    "food_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dataset.Score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dataset.Score.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Since i want to have a binary classification problem with only positive and negative reviews, I will focus mostly on the reviews with 1, 2 as my negative reviews and the reviews with 4, 5 as my positive reviews.For simplicity,  I will dropp all reviews with 3 as i consider them as neutral reviews. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we shall consider all ratings 1, 2 as negative reviews and reviews 4, 5 as positive reviews\n",
    "\n",
    "food_reviews=food_dataset[food_dataset.Score!=3]\n",
    "food_reviews[\"ratings\"]= food_dataset['Score'].apply(lambda x: 1 if x > 3  else 0)\n",
    "food_reviews=food_reviews.drop(\"Score\",axis=1)\n",
    "\n",
    "#food_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_reviews.ratings.value_counts(normalize = True)\n",
    "#Also severely imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this dataset is highly imbalanced. But we will not worrry about it now. We will have to extract an equal number of positive and negative reviews when we are creating our unified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets find some empty cell and delete them\n",
    "food_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTICLASS DATASET CREATION\n",
    "\n",
    "Description:\n",
    "\n",
    "The main aim here was to create a unified dataset(multiclass_customer_review_data), which contains the movie_dataset, the women_dataset and the yelp_dataset into one dataset.\n",
    "\n",
    "We attributed the\n",
    "\n",
    "--- label '0' to the negative examples of all the 3 dataset.\n",
    "\n",
    "--- label '1' for the positive examples from the movie_dataset\n",
    "\n",
    "--- label '2' for the positive examples form the women_dataset\n",
    "\n",
    "--- label '3' for the positive examples form the food_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are aiming for a balanced dataset, we are going to creat a balanced dataset for all the 3 datasets we are using, before creating the unified multiclass dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6c7e051cd10c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Lets get all the positive reviewss together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpositive_movies_reviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmovie_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmovie_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratings\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpositive_clothing_reviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclothing_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclothing_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratings\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'movie_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#Lets get all the positive reviewss together\n",
    "\n",
    "positive_movies_reviews = movie_dataset[movie_dataset.ratings == 1]\n",
    "\n",
    "positive_clothing_reviews = clothing_reviews[clothing_reviews.ratings == 1]\n",
    "positive_clothing_reviews['ratings'].replace(1, 2, inplace = True)\n",
    "\n",
    "positive_food_reviews = food_reviews[food_reviews.ratings == 1]\n",
    "positive_food_reviews['ratings'].replace(1, 3, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column to keep track of the originals in the new datasets\n",
    "\n",
    "positive_movies_reviews['Originally'] = 'Movies'\n",
    "positive_clothing_reviews['Originally'] = 'Clothing'\n",
    "positive_food_reviews['Originally'] = 'Food' \n",
    "\n",
    "#positive_clothing_reviews.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get all the negative reviews together\n",
    "negative_movies_reviews = movie_dataset[movie_dataset.ratings == 0]\n",
    "negative_clothing_reviews = clothing_reviews[clothing_reviews.ratings == 0]\n",
    "negative_food_reviews = food_reviews[food_reviews.ratings == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column to keep track of their original datasets\n",
    "\n",
    "negative_movies_reviews['Originally'] = 'Movies'\n",
    "\n",
    "negative_clothing_reviews['Originally'] = 'Clothing'\n",
    "\n",
    "negative_food_reviews['Originally'] = 'Food'\n",
    "\n",
    "#negative_movies_reviews.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset = pd.concat([positive_movies_reviews, positive_clothing_reviews, positive_food_reviews], axis = 0, ignore_index = True, sort= False)\n",
    "#Dataframes were merged/concatenated correctly. We have no duplicate index.\n",
    "positive_dataset.index[positive_dataset.index.duplicated()].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(df, feature):\n",
    "    total=df.loc[:,feature].value_counts()\n",
    "    percentage=round(df.loc[:,feature].value_counts(normalize = True)*100, 2)\n",
    "    \n",
    "    return pd.concat([total, percentage], axis =1, keys = ['Total', 'Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_values(positive_dataset, 'ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dataset = pd.concat([negative_movies_reviews, negative_clothing_reviews, negative_food_reviews], axis=0, ignore_index = True, sort = False)\n",
    "#Checking\n",
    "negative_dataset.index[negative_dataset.index.duplicated()].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The food dataset is very large and imbalanced. In an attempt to creat a balanced dataset, we will use only a sample of positve data from our 3 caterories of datasets so that we have approximately the same amount of positive and negative data when creating our multicalss daatset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_pos = positive_dataset[positive_dataset['Originally']=='Food'][:65000].append(positive_dataset[positive_dataset['Originally']=='Movies'], ignore_index = True, sort = False)\n",
    "balanced_pos = balanced_pos.append(positive_dataset[positive_dataset['Originally']=='Clothing'], ignore_index = True, sort = False)\n",
    "balanced_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_pos.index[balanced_pos.index.duplicated()].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the positive and negative exxamples to form our multiclass dataset\n",
    "\n",
    "multiclass_dataset = pd.concat([negative_dataset, balanced_pos],ignore_index = True, sort = False)\n",
    "multiclass_dataset = multiclass_dataset.apply(lambda x: x.sample(frac=1).values)#trying to shuffle it a little bit\n",
    "#multiclass_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_dataset.ratings.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how ur unified dataset is distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation library\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import iplot\n",
    "import cufflinks\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "\n",
    "\n",
    "multiclass_dataset['ratings'].value_counts(normalize=True).iplot(kind='bar',\n",
    "                                                      yTitle='Percentages', \n",
    "                                                      linecolor='black', \n",
    "                                                      opacity=0.9,\n",
    "                                                      color='blue',\n",
    "                                                      theme='pearl',\n",
    "                                                      bargap=0.6,\n",
    "                                                      gridcolor='white',\n",
    "                                                     \n",
    "                                                      title='Distribution of Ratings column in the multiclass dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
